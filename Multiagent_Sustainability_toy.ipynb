{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9z7FnP4N9aVZ3qrSXcQ0N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahault/Multi-agent-sustainability/blob/main/Multiagent_Sustainability_toy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment Setup\n",
        "\n",
        "\n",
        "*   Grid Setup: The environment consists of a 3x3 grid.\n",
        "*   Agent Dynamics: Two agents that can move, communicate, and consume resources.\n",
        "*   Resource Dynamics: Water and food are placed randomly and can deplete and replenish.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uWGa5fvQOXcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pettingzoo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqdCeImROn8Y",
        "outputId": "afbef689-b0e8-41fc-ff6f-b23cb3dc4f85"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pettingzoo in /usr/local/lib/python3.10/dist-packages (1.24.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo) (1.25.2)\n",
            "Requirement already satisfied: gymnasium>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo) (0.29.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo) (4.10.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4GegEAtwOQIS"
      },
      "outputs": [],
      "source": [
        "from pettingzoo import AECEnv\n",
        "from pettingzoo.utils import agent_selector\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "\n",
        "class ForagingEnv(AECEnv):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.grid_size = 3\n",
        "        self.n_agents = 2\n",
        "        self.agents = [\"agent_\" + str(i) for i in range(self.n_agents)]\n",
        "        self.agent_selector = agent_selector(self.agents)\n",
        "        self.action_spaces = {agent: spaces.Discrete(6) for agent in self.agents}  # Add one for \"communicate\" action\n",
        "        self.observation_spaces = {agent: spaces.Dict({\n",
        "            \"grid\": spaces.Box(low=0, high=2, shape=(self.grid_size, self.grid_size, 3), dtype=np.float32),\n",
        "            \"state\": spaces.Dict({\n",
        "                \"position\": spaces.MultiDiscrete([self.grid_size, self.grid_size]),\n",
        "                \"water_timer\": spaces.Discrete(3),  # Timesteps until death without water\n",
        "                \"food_timer\": spaces.Discrete(7),  # Timesteps until death without food\n",
        "                \"beliefs\": spaces.Dict({\n",
        "                    \"water_replenish_rate\": spaces.Discrete(10),  # Example max rate\n",
        "                    \"food_replenish_rate\": spaces.Discrete(10),\n",
        "                })\n",
        "            })\n",
        "        }) for agent in self.agents}\n",
        "\n",
        "        self.grid = np.zeros((self.grid_size, self.grid_size, 3), dtype=np.float32)  # Third dimension for agent presence, water, food\n",
        "        self.resource_counters = {\"water\": [np.inf, 0], \"food\": [np.inf, 0]}  # [acquisitions left, replenishment timer]\n",
        "        self.agent_states = {agent: {\"position\": None, \"water_timer\": 3, \"food_timer\": 7, \"beliefs\": {\"water_replenish_rate\": np.inf, \"food_replenish_rate\": np.inf}} for agent in self.agents}\n",
        "        self.current_agent = None\n",
        "\n",
        "    def reset(self):\n",
        "        self.agent_selector.reinit(self.agents)\n",
        "        self.current_agent = self.agent_selector.next()\n",
        "        self.grid *= 0  # Clear the grid\n",
        "\n",
        "        # Randomly place water and food, initialize resource counters\n",
        "        water_position = np.random.choice(self.grid_size**2)\n",
        "        food_position = np.random.choice(self.grid_size**2)\n",
        "        while food_position == water_position:\n",
        "            food_position = np.random.choice(self.grid_size**2)\n",
        "\n",
        "        self.grid[water_position // self.grid_size, water_position % self.grid_size, 1] = 1\n",
        "        self.grid[food_position // self.grid_size, food_position % self.grid_size, 2] = 1\n",
        "        self.resource_counters[\"water\"] = [np.random.randint(1, 5), np.random.randint(5, 15)]  # Random example values\n",
        "        self.resource_counters[\"food\"] = [np.random.randint(1, 5), np.random.randint(5, 15)]\n",
        "\n",
        "        # Set initial positions for agents and reset their states\n",
        "        for i, agent in enumerate(self.agents):\n",
        "            while True:\n",
        "                pos = np.random.choice(self.grid_size**2)\n",
        "                if self.grid[pos // self.grid_size, pos % self.grid_size].sum() == 0:  # Ensure the position is empty\n",
        "                    self.grid[pos // self.grid_size, pos % self.grid_size, 0] = i + 1  # Mark agent's presence\n",
        "                    self.agent_states[agent][\"position\"] = (pos // self.grid_size, pos % self.grid_size)\n",
        "                    self.agent_states[agent][\"water_timer\"] = 3\n",
        "                    self.agent_states[agent][\"food_timer\"] = 7\n",
        "                    break\n",
        "\n",
        "    def step(self, action):\n",
        "      agent = self.current_agent\n",
        "      reward = 0  # Initialize reward for the current step\n",
        "\n",
        "      if action < 4:  # Movement actions\n",
        "          self.move_agent(agent, action)\n",
        "      elif action == 4:  # Consumption action\n",
        "          reward += self.consume_resources(agent)\n",
        "      elif action == 5:  # Communication action\n",
        "          self.communicate(agent)\n",
        "          # Consider if and how communication should affect the reward\n",
        "\n",
        "      # Survival reward for being alive another timestep\n",
        "      reward += 1\n",
        "\n",
        "      # Apply penalties for failing to meet survival requirements\n",
        "      self.agent_states[agent][\"water_timer\"] -= 1\n",
        "      self.agent_states[agent][\"food_timer\"] -= 1\n",
        "      if self.agent_states[agent][\"water_timer\"] <= 0 or self.agent_states[agent][\"food_timer\"] <= 0:\n",
        "          self.terminate_agent(agent)\n",
        "          reward -= 50  # Example penalty for dying\n",
        "\n",
        "      # Move to the next agent\n",
        "      self.current_agent = self.agent_selector.next()\n",
        "\n",
        "      return reward\n",
        "\n",
        "    def move_agent(self, agent, direction):\n",
        "        pos = self.agent_states[agent][\"position\"]\n",
        "        if direction == 0:  # Up\n",
        "            new_pos = (max(pos[0] - 1, 0), pos[1])\n",
        "        elif direction == 1:  # Down\n",
        "            new_pos = (min(pos[0] + 1, self.grid_size - 1), pos[1])\n",
        "        elif direction == 2:  # Left\n",
        "            new_pos = (pos[0], max(pos[1] - 1, 0))\n",
        "        else:  # Right\n",
        "            new_pos = (pos[0], min(pos[1] + 1, self.grid_size - 1))\n",
        "\n",
        "        # Update position if the new position is not occupied\n",
        "        if self.grid[new_pos[0], new_pos[1], 0] == 0:\n",
        "            self.grid[pos[0], pos[1], 0] = 0  # Remove agent from old position\n",
        "            self.grid[new_pos[0], new_pos[1], 0] = 1  # Add agent to new position\n",
        "            self.agent_states[agent][\"position\"] = new_pos\n",
        "\n",
        "    def consume_resources(self, agent):\n",
        "      pos = self.agent_states[agent][\"position\"]\n",
        "      reward = 0\n",
        "      if self.grid[pos[0], pos[1], 1] == 1:  # Water present\n",
        "          self.agent_states[agent][\"water_timer\"] = 3  # Reset water timer\n",
        "          reward += 10  # Example reward for consuming water\n",
        "          # Handle resource depletion logic here\n",
        "      elif self.grid[pos[0], pos[1], 2] == 1:  # Food present\n",
        "          self.agent_states[agent][\"food_timer\"] = 7  # Reset food timer\n",
        "          reward += 10  # Example reward for consuming food\n",
        "          # Handle resource depletion logic here\n",
        "      return reward\n",
        "\n",
        "    def communicate(self, agent):\n",
        "        # Implement logic for agents to communicate their findings and beliefs\n",
        "        pass\n",
        "\n",
        "    def terminate_agent(self, agent):\n",
        "        # Implement logic to remove or disable the agent upon death\n",
        "        pass\n",
        "\n",
        "    def observe(self, agent):\n",
        "        # Return agent-specific observations including both grid and their internal state\n",
        "        observation = self.grid.copy()\n",
        "        agent_state = self.agent_states[agent]\n",
        "        return {\"grid\": observation, \"state\": agent_state}\n",
        "\n",
        "    def render(self, mode=\"human\"):\n",
        "        # Visualize the current state of the environment, including agent positions, resources, and timers\n",
        "        pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage\n",
        "env = ForagingEnv()\n",
        "env.reset()\n",
        "print(env.observe(env.agents[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtu3P44gOlc3",
        "outputId": "06f029a9-e15d-4d2b-82ea-7c00138c453e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'grid': array([[[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]],\n",
            "\n",
            "       [[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]],\n",
            "\n",
            "       [[1., 0., 0.],\n",
            "        [2., 0., 0.],\n",
            "        [0., 1., 0.]]], dtype=float32), 'state': {'position': (2, 0), 'water_timer': 3, 'food_timer': 7, 'beliefs': {'water_replenish_rate': inf, 'food_replenish_rate': inf}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hKabS05hgnKu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}